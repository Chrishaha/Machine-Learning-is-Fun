{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11-1 SVM 思想简介\n",
    "\n",
    "## 章前讨论\n",
    "\n",
    "+ 我们先从线性可分的二分类问题开始叙述，即我们的问题是一个二分类问题，并且可以使用一条“直线”（“平面”或者称为“超平面”）将我们的两类数据集分开。\n",
    "+ 很容易，我们知道决策边界不是唯一的，这样的问题我们又称之为不适定问题。\n",
    "+ 首先回顾一下 Logistic 回归的思路：定义概率函数，然后定义损失函数，损失函数最小化，进而求得决策边界。\n",
    "+ SVM 更多地考虑到模型的泛化能力，对于未知的数据，SVM 期望它有很好的预测能力。\n",
    "\n",
    "下面我们通过几张图来展示我们上面所表述的思想。\n",
    "\n",
    "### 决策边界不唯一\n",
    "\n",
    "+ 对于线性可分的二分类问题而言，决策边界是不唯一的。\n",
    "\n",
    "![](https://liweiwei1419.github.io/images/svm/svm_01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 泛化能力不好的决策边界\n",
    "\n",
    "![](https://liweiwei1419.github.io/images/svm/svm_02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 期望求得的决策边界\n",
    "\n",
    "+ SVM 考虑到机器学习的一个重要的问题：对未知数据的预测，泛化能力。\n",
    "![](https://liweiwei1419.github.io/images/svm/svm_03.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 的一些概念\n",
    "\n",
    "![](https://liweiwei1419.github.io/images/svm/svm_04.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我是如何理解 SVM 的\n",
    "\n",
    "+ 支持向量机就是为了找到泛化能力最好的那个决策边界\n",
    "\n",
    "要严格描述清楚这件事情，须要引入函数间隔和几何间隔的概念来说明。这里我采用一种不同的视角来描述寻找支持向量机的思维过程。\n",
    "\n",
    "我们的目标是找到一条直线，假设我们找到了一条直线，将训练数据集正确划分了。此时，我们让这条直线变得“越来越粗”，“粗”到逼近（马上碰到但是有没有碰到）任何一个数据点（不论正类或者负类）的时候，我们就旋转或者平移这根粗线，然后让它继续变粗，“粗”到逼近任何一个数据点的时候，再旋转或者平移这根粗线，然后让它继续变粗，如此反复。于是，我们最终可以找到一个最粗的直线。这根粗的直线的特点始=是：左边再粗一点点就碰到其中一个类别的点（一个或者多个，一般情况下是一个），右边再粗一点点就碰到另一个类别的点（一个或者多个，一般情况下是一个），这条正好解释了它不能再粗的原因。\n",
    "\n",
    "于是我们就真的让这条粗线左边粗一些，碰到训练数据集中其中一个类别的点，右边粗一点点，碰到训练数据集中另外一个类别的点。左边右边粗一些这件事情，我们可以用两条平行直线来刻画（注意：这里平行的特点很关键），这两条平行直线正中间的那条直线（在它们中间，与它们平行，且距离一样），就是我们要找的最好的划分两类点的直线，就是支持向量机，它是最好的划分两类数据的直线。因为不论是正类还是负类的点，都离这条直线足够远。\n",
    "\n",
    "这里我们引入几个概念（这几个概念在上面的描述中不是很严格，具体定义请翻阅《统计学习方法》和《机器学习》等）：\n",
    "（1）支持向量机：我们刚刚已经说了，就是两条刚好碰到不同分类点的两条平行直线正中间的那条直线；\n",
    "（2）支持向量：那两条平行直线刚好碰到的那些数据点，就叫做支持向量。\n",
    "（3）间隔：那两条平行直线之间的距离的一半。我们通过让这个间隔最大化，来找到最好的分离超平面。\n",
    "\n",
    "总结：\n",
    "支持向量机是一个二类分类的函数，我们从这个函数是直线、平面或者超平面的情况开始研究起，期望找到一个最好的分类直线、平面或者超平面。通过间隔最大化找到支持向量机。间隔最大化就是找到支持向量机的最基本的思路。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
