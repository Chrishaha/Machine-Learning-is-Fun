{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从 sklearn.datasets 中导入 20 类新闻文本抓取器\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 使用新闻抓取器从互联网上下载所有数据，并且存储在变量news中。\n",
    "news = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 对前3000条新闻文本进行数据分割，25% 文本用于未来测试。\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    news.data[:3000], news.target[:3000], test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline 的组成 = 特征提取 + 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入支持向量机（分类）模型。\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 导入TfidfVectorizer文本抽取器。\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 导入Pipeline。\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#使用Pipeline 简化系统搭建流程，将文本抽取与分类器模型串联起来。\n",
    "clf = Pipeline([('vect', TfidfVectorizer(stop_words='english', analyzer='word')), ('svc', SVC())])\n",
    "\n",
    "# 这里需要试验的2个超参数的的个数分别是4、3， svc__gamma的参数共有10^-2, 10^-1... 。这样我们一共有12种的超参数组合，12个不同参数下的模型。\n",
    "parameters = {'svc__gamma': np.logspace(-2, 1, 4), 'svc__C': np.logspace(-1, 1, 3)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Wall time: 51.8 s\n",
      "0.822666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   42.7s finished\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.grid_search中导入网格搜索模块GridSearchCV。\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# 初始化配置并行网格搜索，n_jobs=-1代表使用该计算机全部的CPU。\n",
    "gs = GridSearchCV(clf, parameters, verbose=2, refit=True, cv=3, n_jobs=-1)\n",
    "\n",
    "# 执行多线程并行网格搜索。\n",
    "%time _= gs.fit(X_train, y_train)\n",
    "gs.best_params_, gs.best_score_\n",
    "\n",
    "# 输出最佳模型在测试集上的准确性。\n",
    "print(gs.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
