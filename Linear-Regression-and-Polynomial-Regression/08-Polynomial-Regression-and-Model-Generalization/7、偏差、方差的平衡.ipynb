{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7、偏差、方差的平衡\n",
    "\n",
    "1. 模型误差 = 偏差(Bias) + 方差(Variance) + 不可避免的误差（例如：采集数据本身就有噪音）\n",
    "2. 导致偏差（Bias）的主要原因：对问题本身的假设不正确！如：非线性数据使用线性回归。（我们的假设已经偏离了原问题）。有一些算法天生是高偏差算法。如线性回归。参数学习通常都是高偏差算法。因为对数据具有极强的假设\n",
    "3. 方差（Variance）：方差大的模型，如果对数据产生一点点扰动都会较大地影响模型。通常的原因是，使用的模型太复杂。如高阶多项式回归。过拟合 overfitting 就会引入高方差。有一些算法天生是高方差的算法。如kNN。非参数学习通常都是高方差算法。因为不对数据进行任何假设。\n",
    "4. 大多数算法具有相应的参数，可以调整偏差和方差。如kNN中的k。如线性回归中使用多项式回归。\n",
    "5. 偏差和方差通常是矛盾的。降低偏差，会提高方差。降低方差，会提高偏差。理想的情况是：低偏差、低方差。\n",
    "6. 偏差大，就太偏离原问题。方差大，泛化能力就差。\n",
    "7. 机器学习的主要挑战，来自于方差！\n",
    "8. 解决高方差的通常手段：\n",
    "\n",
    "+ 降低模型复杂度\n",
    "+ 减少数据维度；降噪\n",
    "+ 增加样本数\n",
    "+ 使用验证集\n",
    "+ 模型正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
