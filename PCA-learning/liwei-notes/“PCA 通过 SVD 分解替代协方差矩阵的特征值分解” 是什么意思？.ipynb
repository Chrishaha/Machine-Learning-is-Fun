{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “PCA 通过 SVD 分解替代协方差矩阵的特征值分解” 是什么意思？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在周志华的《机器学习》第 10 章介绍“主成分分析”一节中，有这样一句批注：\n",
    "\n",
    "> 实践中常通过对 $X$ 进行奇异值分解来替代协方差矩阵的特征值分解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就解释一下这句话的意思。\n",
    "\n",
    "如果我们手动做 SVD 分解的话，为了得到 $U$ 或者 $V$，我们要先对 $XX^T$ 或者 $X^TX$ 进行特征值分解，其中 $XX^T$ 就是协方差矩阵。\n",
    "\n",
    "根据\n",
    "$$X^TX = (V \\Sigma^T U^T)(U \\Sigma V^T)=V \\Sigma^T (U^TU) \\Sigma V^T=V \\Sigma^T  \\Sigma V^T$$ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样得到的 $V$ 其实就是我们想要的投影矩阵。这个得到 $V$ 的方法是通过先计算 $X^TX$，再对其做特征值分解得到的。但是 SVD 的经典算法有 Golub-Kahan 算法、分治法、Jacobi 法几种，这些算法其实都比较快，在一些软件底层的实现中，采用的是上述方法中的一种。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，<b><font size='3' color='ff0000'>我们想要的是 $V$，经典算法帮我们快速算出了 $V$，因此就没有必要先算 $X^TX$，再对其做特征值分解了。</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这其实就是书上这句批注的意思，其实很简单。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
