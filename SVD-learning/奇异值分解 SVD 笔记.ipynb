{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 奇异值分解 SVD 笔记\n",
    "\n",
    "Singular Value Decomposition，一般简称为 SVD。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## 参考资料\n",
    "\n",
    "清华大学公开课线性代数2——第3讲：奇异值分解\n",
    "https://blog.csdn.net/you1314520me/article/details/78857469\n",
    "四个子空间。具体做的时候，有什么扩展，看看课本上的例子。\n",
    "\n",
    "参考资料1：奇异值分解(SVD)原理详解及推导\n",
    "https://blog.csdn.net/zhongkejingwang/article/details/43053513\n",
    "\n",
    "参考资料2：SVD在推荐系统中的应用详解以及算法推导\n",
    "https://blog.csdn.net/zhongkejingwang/article/details/43083603\n",
    "\n",
    "\n",
    "刘建平\n",
    "https://www.cnblogs.com/pinard/p/6251584.html\n",
    "\n",
    "\n",
    "参考资料：\n",
    "1、http://charleshm.github.io/2016/03/Singularly-Valuable-Decomposition/\n",
    "数学知识：对称矩阵可以将一组正交基映射到另一组正交基。\n",
    "<b><font size='3' color='ff0000'> SVD 分解的精髓：对任意 m×n 的矩阵，能否找到一组正交基使得经过这个 m×n 的矩阵的变换后还是正交基。</font></b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "参考文章2：http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html\n",
    "奇异值分解是一个有着很明显的物理意义的一种方法，它可以将一个比较复杂的矩阵用更小、更简单的几个子矩阵的相乘来表示，这些小矩阵描述的是矩阵的重要的特性。就像是描述一个人一样，给别人描述说这个人长得浓眉大眼，方脸，络腮胡，而且带个黑框的眼镜，这样寥寥的几个特征，就让别人脑海里面就有一个较为清楚的认识，实际上，人脸上的特征是有着无数种的，之所以能这么描述，是因为人天生就有着非常好的抽取重要特征的能力，让机器学会抽取重要的特征，SVD是一个重要的方法。\n",
    "（我的思考，那是不是 PCA 也是这样的，抽取重要的特征）\n",
    "\n",
    "\n",
    "奇异值，跟特征值类似，在矩阵Σ中也是从大到小排列，而且σ的减少特别的快，在很多情况下，前 10% 甚至 1% 的奇异值的和就占了全部的奇异值之和的 99% 以上了。也就是说，我们也可以用前 r 大的奇异值来近似描述矩阵，这里定义一下部分奇异值分解：\n",
    "\n",
    "\n",
    "（<b><font size='3' color='ff0000'>注意：这个定义不太一样！！！）右边的三个矩阵相乘的结果将会是一个接近于A的矩阵，在这儿，r越接近于n，则相乘的结果越接近于A。而这三个矩阵的面积之和（在存储观点来说，矩阵面积越小，存储量就越小）要远远小于原始的矩阵A，我们如果想要压缩空间来表示原矩阵A，我们存下这里的三个矩阵：U、Σ、V就好了。\n",
    "\n",
    "\n",
    "参考资料3：http://blog.sciencenet.cn/blog-696950-699432.html\n",
    "这篇文章讲解了奇异值分解的几何意义和应用。\n",
    "\n",
    "\n",
    "http://shartoo.github.io/SVD-decomponent/\n",
    "\n",
    "奇异值分解可以用于图像压缩。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size='3' color='ff0000'>SVD 分解就是利用隐藏的 feature 建立起矩阵行和列之间的联系。</font></b>\n",
    "\n",
    "理解这里的 <b><font size='3' color='ff0000'>隐藏的 feature</font></b> 和 其重要性的意义。\n",
    "\n",
    "\n",
    "主成分分析就是对数据的协方差矩阵进行了类似的分解（特征值分解），但这种分解只适用于对称的矩阵，而 SVD 则是对任意大小和形状的矩阵都成立。\n",
    "\n",
    "https://cosx.org/2014/02/svd-and-image-compression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路：往对称矩阵上面靠。对于任意的矩阵 $A$ 来说，$A^TA$ 和 $AA^T$ 都是对称矩阵。\n",
    "\n",
    "$$\n",
    "U \\Sigma = AV\n",
    "$$\n",
    "\n",
    "\n",
    "$U \\Sigma$ 是 $m \\times n$ 矩阵，$AV$ 也是 $m \\times n$ 矩阵。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./SVD-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./SVD-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 与 SVD\n",
    "\n",
    "![](./PCA 与 SVD.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、矩阵作为**线性变换**有两个效果（1）旋转（2）伸缩；\n",
    "\n",
    "2、SVD 可以达到的效果：用 SVD 可以很容易得到任意矩阵的满秩分解，用满秩分解可以对数据做压缩。可以用 SVD 来证明对任意 M*N 的矩阵均存在如下分解：\n",
    "\n",
    "原始矩阵 A 的秩等于非零奇异值的个数。\n",
    "\n",
    "SVD 应用在<b><font size='3' color='ff0000'>数据降维压缩</font></b>上！在数据相关性特别大的情况下存储 X 和 Y 矩阵比存储 A 矩阵占用空间更小！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、正交矩阵（对应正交变换），重要特点：<b><font size='3' color='ff0000'>不改变向量的长度</font></b>和<b><font size='3' color='ff0000'>向量间的夹角</font></b>。\n",
    "正交矩阵的行（列）向量都是两两正交的<b><font size='3' color='ff0000'>单位</font></b>向量，正交矩阵对应的变换为正交变换，它有两种表现：旋转和反射。正交矩阵将标准正交基映射为标准正交基。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正交矩阵：若一个方阵其行与列皆为正交的单位向量，则该矩阵为正交矩阵，且该矩阵的转置和其逆相等。两个向量正交的意思是两个向量的内积为 0。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、对称阵有一个很优美的性质：它总能相似对角化，对称阵不同特征值对应的特征向量两两正交。一个矩阵能相似对角化即说明其特征子空间即为其列空间，若不能对角化则其特征子空间为列空间的子空间。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5、推导的过程简述如下：\n",
    "\n",
    "假设 $$A = U \\Sigma V^T$$\n",
    "\n",
    "其中：\n",
    "1、$A$  是一个秩为 $r$ 的 $m \\times n$  矩阵；\n",
    "\n",
    "2、$U$ 是一个 $m \\times m$ 矩阵，并且还是一个正交矩阵，即这个矩阵的列向量相互正交，并且模为 $1$，$U^TU=E$ 从定义就可以知道；\n",
    "\n",
    "3、$\\Sigma$ 是一个 $m \\times n$ 矩阵，并且是一个对角矩阵，主对角线的元素均非负，并且<b><font size='3' color='ff0000'>从大到小排列</font></b>，前 $r$ 个元素是正数（和前面 $A$ 的秩是 $r$ 对应）；\n",
    "\n",
    "\n",
    "4、$V$ 是一个 $n \\times n$ 矩阵，并且还是一个正交矩阵（列向量相互正交，并且模为 1）。\n",
    "\n",
    "\n",
    "用待定系数法探索 $U$ 、$\\Sigma$ 和 $V$ 应该满足的性质。\n",
    "对于任意的矩阵 $A$ 来说， $A^TA$ 和 $AA^T$ 都是对称矩阵，并且根据已知可以得到：$A^T=V \\Sigma^TU^T$，并且已知 $\\Sigma$ 是“对角阵”，那么 $\\Sigma$ 一定是“对称矩阵”，这样其实是不严谨的，中间对角阵的型号不一样。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A^TA = (V \\Sigma^TU^T)(U \\Sigma V^T) = V \\Sigma^T\\Sigma V^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "AA^T = (U \\Sigma V^T)(V \\Sigma^TU^T) = U \\Sigma\\Sigma^T U^T\n",
    "$$\n",
    "\n",
    "以上两个等式正好就是两个对称矩阵 $A^TA$ 和 $AA^T$ 的特征值分解。所以，很容易知道，<b><font size='3' color='ff0000'>它们的特征值中非零的部分是相等的</font></b>，并且 ，且 $A^TA$ 的特征向量按列排成矩阵 $V$，$AA^T$ 的特征向量按列排成矩阵 $U$。奇异值是 $\\Sigma^T\\Sigma$ 和 $\\Sigma^T\\Sigma$ 中正的那部分的开方。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
