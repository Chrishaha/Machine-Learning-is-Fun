{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n",
      "[10  3 17 ...  3  1  7]\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "print(len(news.data))\n",
    "print(news.data[0])\n",
    "print(news.target)\n",
    "print(news.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(news.data,news.target,test_size =0.25,random_state = 666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用朴素贝叶斯分类器\n",
    "\n",
    "+ 首先要做数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "X_train_count_vec = count_vec.fit_transform(X_train)\n",
    "X_test_count_vec =count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.85      0.87       225\n",
      "          1       0.71      0.87      0.79       250\n",
      "          2       1.00      0.10      0.18       249\n",
      "          3       0.64      0.82      0.72       236\n",
      "          4       0.85      0.86      0.86       246\n",
      "          5       0.68      0.90      0.77       257\n",
      "          6       0.90      0.69      0.78       234\n",
      "          7       0.93      0.92      0.92       268\n",
      "          8       0.97      0.93      0.95       238\n",
      "          9       0.97      0.94      0.95       224\n",
      "         10       0.97      0.98      0.97       240\n",
      "         11       0.83      0.98      0.90       249\n",
      "         12       0.86      0.79      0.82       263\n",
      "         13       0.94      0.94      0.94       251\n",
      "         14       0.88      0.94      0.91       260\n",
      "         15       0.71      0.98      0.83       212\n",
      "         16       0.86      0.95      0.90       233\n",
      "         17       0.91      0.98      0.94       233\n",
      "         18       0.83      0.88      0.86       190\n",
      "         19       0.91      0.44      0.59       154\n",
      "\n",
      "avg / total       0.86      0.84      0.83      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_count_vec,y_train)\n",
    "count_vec_y_predict = mnb.predict(X_test_count_vec)\n",
    "\n",
    "print(classification_report(y_test,count_vec_y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vec.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.60      0.72       225\n",
      "          1       0.89      0.74      0.81       250\n",
      "          2       0.85      0.85      0.85       249\n",
      "          3       0.71      0.84      0.77       236\n",
      "          4       0.92      0.84      0.88       246\n",
      "          5       0.91      0.82      0.87       257\n",
      "          6       0.91      0.69      0.79       234\n",
      "          7       0.95      0.92      0.94       268\n",
      "          8       0.92      0.97      0.94       238\n",
      "          9       0.93      0.96      0.94       224\n",
      "         10       0.95      0.99      0.97       240\n",
      "         11       0.78      1.00      0.87       249\n",
      "         12       0.90      0.75      0.82       263\n",
      "         13       0.94      0.89      0.92       251\n",
      "         14       0.90      0.94      0.92       260\n",
      "         15       0.42      0.99      0.59       212\n",
      "         16       0.79      0.94      0.86       233\n",
      "         17       0.93      0.98      0.95       233\n",
      "         18       0.99      0.53      0.69       190\n",
      "         19       0.97      0.21      0.34       154\n",
      "\n",
      "avg / total       0.87      0.84      0.83      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf,y_train)\n",
    "tfidf_vec_predict = mnb.predict(X_test_tfidf)\n",
    "print(classification_report(y_test,tfidf_vec_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  0,  4, ..., 11,  8,  5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
